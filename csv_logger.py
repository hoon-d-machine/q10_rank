import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import os
import time

HEADERS = {'user-agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1','accept': 'application/json, text/plain, */*',
    'referer': 'https://m.qoo10.jp/',}

def update_csv(df, file_name):
    if df is None or df.empty: return
    file_path = f"data/{file_name}"
    os.makedirs("data", exist_ok=True)
    
    df['ìˆœìœ„'] = df['ìˆœìœ„'].astype(int)
    
    if os.path.exists(file_path):
        old_df = pd.read_csv(file_path)
        updated_df = pd.concat([old_df, df], ignore_index=True)
        # ì¤‘ë³µ ê¸°ì¤€ì—ì„œ ìƒí’ˆID ì œì™¸
        subset = ['ì¼ì', 'ìˆœìœ„', 'ì¹´í…Œê³ ë¦¬', 'ìƒí’ˆëª…'] if 'ì¹´í…Œê³ ë¦¬' in df.columns else ['ì¼ì', 'ìˆœìœ„', 'ìƒí’ˆëª…']
        updated_df = updated_df.drop_duplicates(subset=subset, keep='last')
    else:
        updated_df = df
    
    updated_df.to_csv(file_path, index=False, encoding='utf-8-sig')

def get_daily_bestsellers():
    url = 'https://m.qoo10.jp/gmkt.inc/BestSellers/?g=2'
    res = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(res.text, 'html.parser')
    items = soup.select('li[data_gd_no]')
    data = []
    for item in items:
        try:
            rank = int(item.select_one('.rank_current').text.strip())
            if rank > 200: continue
            data.append({
                "ì¼ì": datetime.now().strftime('%Y-%m-%d'),
                "ìˆœìœ„": rank,
                "ì¹´í…Œê³ ë¦¬": "ë°ì¼ë¦¬ ë·°í‹°",
                "ë¸Œëœë“œ": item.select_one('.common_ui_seller_brand').text.strip() if item.select_one('.common_ui_seller_brand') else "",
                "ìƒí’ˆëª…": item.select_one('.list_v2_title').text.strip(),
                "ê°€ê²©": int(item.select_one('.price_final_value').text.strip().replace(',', ''))
            })
        except: continue
    return pd.DataFrame(data)

def get_official_ranking(period):
    categories = {'ì „ì²´': None, 'ìŠ¤í‚¨ì¼€ì–´': '120000012', 'ë² ì´ìŠ¤': '120000013', 'í¬ì¸íŠ¸': '120000014'}
    url = 'https://m.qoo10.jp/gmkt.inc/Mobile/Beauty/OfficialRanking.aspx/GetBestSellerBeautyOfficialRanking'
    all_data = []
    period_name = "ì£¼ê°„" if period == 'W' else "ì›”ê°„"
    
    for name, code in categories.items():
        payload = {'gdlcCd': code, 'gdmcCd': None, 'gdscCd': None, 'period': period, 'pageNo': 1, 'pageSize': 100, 'showMegaoshi': 'Y', '___cache_expire___': str(int(time.time()*1000))}
        res = requests.post(url, headers=HEADERS, json=payload)
        items = res.json().get('d', {}).get('goods', [])
        for item in items:
            all_data.append({
                "ì¼ì": datetime.now().strftime('%Y-%m-%d'),
                "ìˆœìœ„": int(item.get("ROW_NUMBER")),
                "ì¹´í…Œê³ ë¦¬": f"{name}_{period_name}",
                "ë¸Œëœë“œ": item.get("BRAND_INFO", {}).get("BRAND_NM", ""),
                "ìƒí’ˆëª…": item.get("GD_NM", ""),
                "ê°€ê²©": int(item.get("FINAL_PRICE", 0))
            })
    return pd.DataFrame(all_data)

if __name__ == "__main__":
    now = datetime.now()
    print("ğŸš€ ì „ì²´ ìˆ˜ì§‘ ì‹œì‘...")
    update_csv(get_daily_bestsellers(), "bestseller_daily.csv")
    if now.weekday() == 0 or not os.path.exists("data/official_weekly.csv"):
        print("2. ì£¼ê°„ ë­í‚¹ ìˆ˜ì§‘ ì¤‘...")
        update_csv(get_official_ranking('W'), "official_weekly.csv")
    if now.day == 1 or not os.path.exists("data/official_monthly.csv"):
        print("3. ì›”ê°„ ë­í‚¹ ìˆ˜ì§‘ ì¤‘...")
        update_csv(get_official_ranking('M'), "official_monthly.csv")
        print("âœ¨ ëª¨ë“  ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
